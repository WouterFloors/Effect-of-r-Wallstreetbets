# -*- coding: utf-8 -*-
"""WallStreetBets API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18a7PtrnxmrXQFZkeh5jBcvyNKvJL6cds
"""

import csv 
import time
from datetime import date
import requests


def write_headers():
    count_headers = 0
    if count_headers == 0:
      with open("reddit_wsb_api.csv", "a", newline='') as csv_file:
              writer = csv.writer(csv_file, delimiter = "\t")
              writer.writerow(["ticker", "no_of_comments", "sentiment", "sentiment_score", "date", "unix"])
              csv_file.close()
    count_headers = count_headers + 1


#Get data from API
def get_data():
    url = 'https://dashboard.nbshare.io/api/v1/apps/reddit'
    response = requests.get(url)
    json_response = response.json()

    #Write to CSV file in append mode
    with open("reddit_wsb_api.csv", "a", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter = "\t")
        datetoday = date.today()
        timenow = time.time()
        for content in json_response:
            writer.writerow([content['ticker'], content['no_of_comments'], content['sentiment'], content['sentiment_score'], datetoday, timenow])
        csv_file.close()

#rather use scheduling; see https://tilburgsciencehub.com/schedule/task

print('done!')

write_headers()
print('written headers!')

get_data()
print('data gotten!')